{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "\n",
    "from src.architecture import FootpathModelArchitecture\n",
    "from src.miscellaneous import load_random_image, preprocess_image\n",
    "from src.training_preparation import (create_checkpoint_callback,\n",
    "                                      create_training_dataset, load_image_test,\n",
    "                                      load_image_train, load_vgg16_weights,\n",
    "                                      map_to_masks, sum_up_training_dataset,\n",
    "                                      sum_up_validation_dataset)\n",
    "from src.visualization import create_overlay, display_images\n",
    "from src.transfer_learning_preparation import freeze_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_directory = './parameters/'\n",
    "transfer_learning_parameter_file = 'transfer_learning.json'\n",
    "parameter_path = parameter_directory + transfer_learning_parameter_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parameter_path) as parameter_file:\n",
    "    transfer_learning_parameters = json.load(parameter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parameters = transfer_learning_parameters['initial']\n",
    "data_parameters = transfer_learning_parameters['data']\n",
    "input_parameters = transfer_learning_parameters['input']\n",
    "compiler_parameters = transfer_learning_parameters['compiler']\n",
    "solver_parameters = transfer_learning_parameters['solver']\n",
    "output_parameters = transfer_learning_parameters['output']\n",
    "testing_parameters = transfer_learning_parameters['testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_TRAINING_IMAGES = len(os.listdir(data_parameters['training_data_directory'] +\n",
    "                                           data_parameters['training_image_folder']))\n",
    "NUMBER_OF_VALIDATION_IMAGES = len(os.listdir(data_parameters['training_data_directory'] +\n",
    "                                             data_parameters['validation_image_folder']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = NUMBER_OF_TRAINING_IMAGES + 1\n",
    "TRAINING_STEPS = NUMBER_OF_TRAINING_IMAGES\n",
    "VALIDATION_STEPS = NUMBER_OF_VALIDATION_IMAGES\n",
    "SAVE_CHECKPOINT_STEPS = NUMBER_OF_TRAINING_IMAGES * solver_parameters['save_checkpoints_steps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model structure and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (input_parameters['width'], input_parameters['height'], input_parameters['channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footpath_model = FootpathModelArchitecture(input_shape).footpath_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (initial_parameters['format'] == 'h5'):\n",
    "    footpath_model.load_weights(initial_parameters['intial_weight_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = create_training_dataset(data_parameters['training_data_directory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_data['training']\n",
    "training_set = training_set.map(lambda training_set: load_image_train(training_set,\n",
    "                                                                      (input_parameters['width'],\n",
    "                                                                       input_parameters['height'])))\n",
    "validation_set = training_data['validation']\n",
    "validation_set = validation_set.map(lambda validation_set: load_image_test(validation_set,\n",
    "                                                                           (input_parameters['width'],\n",
    "                                                                            input_parameters['height'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = sum_up_training_dataset(training_set, buffer_size=BUFFER_SIZE,\n",
    "                                       batch_size=solver_parameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = sum_up_validation_dataset(validation_set, \n",
    "                                           batch_size=solver_parameters['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show samples of training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, sample in enumerate(training_set.take(1)):\n",
    "    original_image = sample[0]\n",
    "    mask = sample[1]\n",
    "\n",
    "    overlay = create_overlay(original_image, mask)\n",
    "    display_images([original_image, mask, overlay], ['origin', 'mask', 'overlay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, sample in enumerate(validation_set.take(1)):\n",
    "    original_image = sample[0]\n",
    "    mask = sample[1]\n",
    "    \n",
    "    overlay = create_overlay(original_image, mask)\n",
    "    display_images([original_image, mask, overlay], ['origin', 'mask', 'overlay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory = (output_parameters['output_folder'] +\n",
    "                 output_parameters['log_folder'] +\n",
    "                 datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = (output_parameters['output_folder'] + output_parameters['checkpoint_folder'])\n",
    "checkpoint_callback = create_checkpoint_callback(checkpoint_directory,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='binary_crossentropy',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_freq=SAVE_CHECKPOINT_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = solver_parameters['epochs'] - (solver_parameters['epochs'] // 3)\n",
    "adjusted_learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, initial_learning_rate, limit, adjusted_learning_rate):\n",
    "    if (limit == 0):\n",
    "        return initial_learning_rate\n",
    "    elif (epoch < limit):\n",
    "        return initial_learning_rate\n",
    "    else:\n",
    "        return adjusted_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_callback = LearningRateScheduler(lambda epoch: scheduler(epoch, \n",
    "                                                                       compiler_parameters['learning_rate'], \n",
    "                                                                       limit, \n",
    "                                                                       adjusted_learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layers(footpath_model, initial_parameters['freezed_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which layers remain trainable\n",
    "for layer in footpath_model.layers:\n",
    "    if (layer.trainable):\n",
    "        print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footpath_model.compile(optimizer=Adam(learning_rate=compiler_parameters['learning_rate'],\n",
    "                                      epsilon=compiler_parameters['epsilon']),\n",
    "                       loss=BinaryCrossentropy(from_logits=False),\n",
    "                       metrics=[tf.keras.metrics.BinaryCrossentropy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = footpath_model.fit(training_set,\n",
    "                                   epochs=solver_parameters['epochs'],\n",
    "                                   steps_per_epoch=TRAINING_STEPS,\n",
    "                                   validation_steps=VALIDATION_STEPS,\n",
    "                                   validation_data=validation_set,\n",
    "                                   callbacks=[checkpoint_callback, tensorboard_callback, learning_rate_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final weights and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_directory = output_parameters['output_folder'] + output_parameters['output_model']\n",
    "weights_directory = output_parameters['output_folder'] + output_parameters['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footpath_model.save(filepath=output_model_directory)\n",
    "footpath_model.save_weights(filepath=weights_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
